import os
import glob
from tqdm import tqdm
from config import Config
from utils import load_json, save_json, validate_structure, chunk_list, detect_text_field
from proofreader import Proofreader
import json

def generate_summary_report(reports):
    """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
    total_items = len(reports)
    correct_items = sum(1 for r in reports if r.get('is_correct', False))
    incorrect_items = total_items - correct_items

    avg_score = sum(r.get('score', 0) for r in reports) / total_items if total_items > 0 else 0
    
    # ç»Ÿè®¡ä¿®æ”¹çº§åˆ«
    modification_levels = {}
    for report in reports:
        level = report.get('modification_level', 'æœªçŸ¥')
        modification_levels[level] = modification_levels.get(level, 0) + 1

    # ç»Ÿè®¡é—®é¢˜ç±»å‹
    issue_types = {}
    for report in reports:
        for issue in report.get('issues', []):
            issue_type = issue.get('type', 'æœªçŸ¥')
            issue_types[issue_type] = issue_types.get(issue_type, 0) + 1

    summary = {
        "summary": {
            "total_items": total_items,
            "correct_items": correct_items,
            "incorrect_items": incorrect_items,
            "accuracy_rate": round(correct_items / total_items * 100, 2) if total_items > 0 else 0,
            "average_score": round(avg_score, 2),
            "issue_statistics": issue_types,
            "modification_statistics": modification_levels
        },
        "detailed_reports": reports
    }

    return summary

def find_matching_files(en_folder, zh_folder):
    """æŸ¥æ‰¾åŒ¹é…çš„ä¸­è‹±æ–‡æ–‡ä»¶å¯¹"""
    en_files = {}
    zh_files = {}
    
    # æ”¶é›†è‹±æ–‡æ–‡ä»¶
    for file_path in glob.glob(os.path.join(en_folder, "*.json")):
        filename = os.path.basename(file_path)
        # ç§»é™¤å¯èƒ½çš„åç¼€
        base_name = filename.replace('_en.json', '').replace('.json', '')
        en_files[base_name] = file_path
    
    # æ”¶é›†ä¸­æ–‡æ–‡ä»¶
    for file_path in glob.glob(os.path.join(zh_folder, "*.json")):
        filename = os.path.basename(file_path)
        # ç§»é™¤å¯èƒ½çš„åç¼€
        base_name = filename.replace('_zh-sc.json', '').replace('.json', '')
        zh_files[base_name] = file_path
    
    # æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶å¯¹
    file_pairs = []
    for base_name in en_files:
        if base_name in zh_files:
            file_pairs.append({
                'base_name': base_name,
                'en_file': en_files[base_name],
                'zh_file': zh_files[base_name]
            })
    
    return file_pairs

def select_files_interactive(file_pairs):
    """äº¤äº’å¼é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶"""
    if not file_pairs:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶å¯¹")
        return []
    
    print("\nğŸ“‹ å¯ç”¨çš„æ–‡ä»¶å¯¹:")
    for i, pair in enumerate(file_pairs, 1):
        print(f"{i}. {pair['base_name']}")
        print(f"   ä¸­æ–‡: {os.path.basename(pair['zh_file'])}")
        print(f"   è‹±æ–‡: {os.path.basename(pair['en_file'])}")
    
    print(f"\nğŸ’¡ è¾“å…¥é€‰é¡¹ç¼–å·(ç”¨ç©ºæ ¼åˆ†éš”)ï¼Œæˆ–è¾“å…¥'all'å¤„ç†æ‰€æœ‰æ–‡ä»¶:")
    user_input = input("è¯·é€‰æ‹©: ").strip()
    
    if user_input.lower() == 'all':
        return file_pairs
    
    try:
        selected_indices = [int(x.strip()) - 1 for x in user_input.split() if x.strip()]
        selected_pairs = [file_pairs[i] for i in selected_indices if 0 <= i < len(file_pairs)]
        return selected_pairs
    except ValueError:
        print("âŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·è¾“å…¥æ•°å­—æˆ–'all'")
        return []

def process_file_pair(en_file, zh_file, proofreader):
    """å¤„ç†å•ä¸ªæ–‡ä»¶å¯¹"""
    print(f"\nğŸ”„ æ­£åœ¨å¤„ç†æ–‡ä»¶å¯¹: {os.path.basename(en_file)} <-> {os.path.basename(zh_file)}")
    
    try:
        src = load_json(zh_file)
        tgt = load_json(en_file)
        # ä¿å­˜åŸå§‹ç¿»è¯‘æ•°æ®ç”¨äºåç»­ä¿®æ”¹
        original_tgt = load_json(en_file)
    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        return None
    except json.JSONDecodeError as e:
        print(f"âŒ JSONæ ¼å¼é”™è¯¯: {e}")
        return None

    print(f"ğŸ“„ ä¸­æ–‡æ¡æ•°: {len(src)}")
    print(f"ğŸ“„ è‹±æ–‡æ¡æ•°: {len(tgt)}")

    try:
        validate_structure(src, tgt)
    except (ValueError, KeyError) as e:
        print(f"âŒ æ•°æ®ç»“æ„éªŒè¯å¤±è´¥: {e}")
        return None

    print("ğŸ”„ æ­£åœ¨åˆå¹¶æ•°æ®...")
    merged = []
    for i, (s, t) in enumerate(zip(src, tgt)):
        source_field = detect_text_field(s)
        target_field = detect_text_field(t)
        
        if not source_field or not target_field:
            print(f"âš  ç¬¬{i}æ¡å­—æ®µå¼‚å¸¸ï¼Œè·³è¿‡")
            continue
            
        # å®‰å…¨åœ°è·å–å’Œå¤„ç†æ–‡æœ¬å†…å®¹
        try:
            source_value = s[source_field]
            target_value = t[target_field]
            
            # ç¡®ä¿è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶å»é™¤ç©ºç™½
            source_text = str(source_value).strip() if source_value is not None else ""
            target_text = str(target_value).strip() if target_value is not None else ""
            
            # éªŒè¯æ–‡æœ¬ä¸ä¸ºç©º
            if not source_text or not target_text:
                print(f"âš  ç¬¬{i}æ¡æ–‡æœ¬å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡")
                continue
                
            merged.append({
                "index": i,
                "name": s.get("name"),
                "source": source_text,
                "target": target_text
            })
            
        except Exception as e:
            print(f"âš  ç¬¬{i}æ¡æ•°æ®å¤„ç†å‡ºé”™: {e}")
            continue

    if not merged:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®å¯ä»¥å¤„ç†")
        return None

    print(f"âœ… åˆå¹¶å®Œæˆï¼Œå…± {len(merged)} æ¡å¾…æ ¡å¯¹")

    all_reports = []
    print("ğŸ¤– å¼€å§‹AIæ ¡å¯¹...")
    
    batch_count = 0
    for batch in tqdm(list(chunk_list(merged, Config.BATCH_SIZE)), desc="å¤„ç†æ‰¹æ¬¡"):
        batch_count += 1
        try:
            reports = proofreader.proofread_batch(batch)
            all_reports.extend(reports)
        except Exception as e:
            print(f"âŒ æ‰¹æ¬¡ {batch_count} å¤„ç†å¤±è´¥: {e}")
            # ä¸ºå¤±è´¥çš„æ‰¹æ¬¡åˆ›å»ºé”™è¯¯æŠ¥å‘Š
            for item in batch:
                all_reports.append({
                    "original_index": item['index'],
                    "name": item['name'],
                    "source_text": item['source'],
                    "target_text": item['target'],
                    "score": 0,
                    "modified_text": item['target'],
                    "comment": f"æ‰¹æ¬¡å¤„ç†å¤±è´¥: {str(e)}",
                    "is_correct": False,
                    "error": str(e)
                })
    
    return {
        'src_data': src,
        'tgt_data': tgt,
        'original_tgt': original_tgt,
        'reports': all_reports,
        'filename': os.path.basename(en_file)
    }

def run():
    print("ğŸ”„ æ­£åœ¨æ‰«æè¾“å…¥æ–‡ä»¶å¤¹...")
    
    EN_FOLDER = "input_en"
    ZH_FOLDER = "input_zh-sc"
    MODIFIED_FOLDER = "output/en_modified"
    REPORT_FOLDER = "report"
    
    # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
    if not os.path.exists(EN_FOLDER):
        print(f"âŒ è‹±æ–‡è¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {EN_FOLDER}")
        return
    if not os.path.exists(ZH_FOLDER):
        print(f"âŒ ä¸­æ–‡è¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {ZH_FOLDER}")
        return
    
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    os.makedirs(MODIFIED_FOLDER, exist_ok=True)
    os.makedirs(REPORT_FOLDER, exist_ok=True)
    
    # æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶å¯¹
    file_pairs = find_matching_files(EN_FOLDER, ZH_FOLDER)
    
    if not file_pairs:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶å¯¹")
        return
    
    # ç”¨æˆ·é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶
    selected_pairs = select_files_interactive(file_pairs)
    
    if not selected_pairs:
        print("âŒ æ²¡æœ‰é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶")
        return
    
    print(f"\nâœ… å·²é€‰æ‹© {len(selected_pairs)} ä¸ªæ–‡ä»¶å¯¹è¿›è¡Œå¤„ç†")
    
    proofreader = Proofreader()
    all_results = []
    
    # å¤„ç†æ¯ä¸ªé€‰ä¸­çš„æ–‡ä»¶å¯¹
    for pair in selected_pairs:
        result = process_file_pair(pair['en_file'], pair['zh_file'], proofreader)
        if result:
            # æ·»åŠ æ–‡ä»¶åä¿¡æ¯ç”¨äºæŠ¥å‘Šå‘½å
            result['base_name'] = pair['base_name']
            all_results.append(result)
    
    if not all_results:
        print("âŒ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ–‡ä»¶")
        return

    # å¤„ç†æ‰€æœ‰ç»“æœå¹¶ç”ŸæˆæŠ¥å‘Š
    total_modified = 0
    all_detailed_reports = []
    
    # ä¸ºæ¯ä¸ªæ–‡ä»¶ç”Ÿæˆå•ç‹¬çš„æŠ¥å‘Šå¹¶åœ¨outputä¸­åˆ›å»ºä¿®æ”¹åçš„å‰¯æœ¬
    for result in all_results:
        reports = result['reports']
        original_tgt = result['original_tgt']
        filename = result['filename']
        base_name = result['base_name']
        
        # åˆ›å»ºä¿®æ”¹åçš„è‹±æ–‡æ–‡ä»¶å‰¯æœ¬
        modified_count = 0
        for report in reports:
            original_index = report['original_index']
            if report['target_text'] != report['modified_text']:
                # æ›´æ–°ç¿»è¯‘æ–‡ä»¶ä¸­çš„å¯¹åº”æ¡ç›®
                target_field = detect_text_field(original_tgt[original_index])
                if target_field:
                    original_tgt[original_index][target_field] = report['modified_text']
                    modified_count += 1
        
        # ä¿å­˜ä¿®æ”¹åçš„ç¿»è¯‘æ–‡ä»¶åˆ°output/en_modified/
        modified_filename = filename
        save_json(original_tgt, os.path.join(MODIFIED_FOLDER, modified_filename))
        total_modified += modified_count
        
        # ä¸ºè¯¥æ–‡ä»¶ç”Ÿæˆå•ç‹¬çš„æŠ¥å‘Š
        file_report = {
            "file_info": {
                "filename": filename,
                "base_name": base_name,
                "total_items": len(reports),
                "modified_items": modified_count
            },
            "reports": reports
        }
        
        # ä¿å­˜å•ç‹¬çš„æŠ¥å‘Šæ–‡ä»¶
        report_filename = f"{base_name}_report.json"
        save_json(file_report, os.path.join(REPORT_FOLDER, report_filename))
        
        # æ·»åŠ åˆ°æ€»æŠ¥å‘Š
        all_detailed_reports.extend(reports)
        
        print(f"ğŸ“ {filename}: ä¿®æ”¹äº† {modified_count} æ¡")
    
    # ç”Ÿæˆæ€»æ±‡æ€»æŠ¥å‘Š
    summary_report = generate_summary_report(all_detailed_reports)
    
    # ä¿å­˜æ€»æŠ¥å‘Š
    total_report_path = os.path.join(REPORT_FOLDER, "summary_report.json")
    save_json(summary_report, total_report_path)

    print("====================================")
    print("âœ… æ ¡å¯¹å®Œæˆ")
    print(f"ğŸ“Š æ€»æ¡æ•°: {summary_report['summary']['total_items']}")
    print(f"âœ… æ­£ç¡®æ¡æ•°: {summary_report['summary']['correct_items']}")
    print(f"âŒ é”™è¯¯æ¡æ•°: {summary_report['summary']['incorrect_items']}")
    print(f"ğŸ“ˆ å‡†ç¡®ç‡: {summary_report['summary']['accuracy_rate']}%")
    print(f"â­ å¹³å‡åˆ†: {summary_report['summary']['average_score']}")
    print(f"âœï¸  æ€»å…±ä¿®æ”¹æ¡ç›®: {total_modified}æ¡")
    
    print(f"\nğŸ“‚ è¾“å‡ºä½ç½®:")
    print(f"  ä¿®æ”¹åçš„æ–‡ä»¶: {MODIFIED_FOLDER}")
    print(f"  å•ç‹¬æŠ¥å‘Šæ–‡ä»¶: {REPORT_FOLDER}")
    print(f"  æ€»æŠ¥å‘Šæ–‡ä»¶: {total_report_path}")
    print(f"ğŸ“ è¾“å…¥æ–‡ä»¶å¤¹: {EN_FOLDER}, {ZH_FOLDER} (æœªä¿®æ”¹)")
    print("====================================")

if __name__ == "__main__":
    run()
